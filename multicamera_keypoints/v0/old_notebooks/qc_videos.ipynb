{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d1c2b1a",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Detections-only\" data-toc-modified-id=\"Detections-only-1\">Detections only</a></span></li><li><span><a href=\"#GIMBAL-only\" data-toc-modified-id=\"GIMBAL-only-2\">GIMBAL only</a></span></li><li><span><a href=\"#Stages-videos\" data-toc-modified-id=\"Stages-videos-3\">Stages videos</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "confidential-happening",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import sys\n",
    "import glob\n",
    "# import gimbal\n",
    "import joblib\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "import numpy as np\n",
    "import joblib, json, os, h5py\n",
    "from os.path import join, exists\n",
    "import imageio, cv2\n",
    "import tqdm.auto as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import multicam_calibration as mcc\n",
    "import keypoint_moseq as kpms\n",
    "from scipy.ndimage import median_filter, gaussian_filter1d\n",
    "from vidio.read import OpenCVReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7450c3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "def build_node_hierarchy(bodyparts, skeleton, root_node):\n",
    "    \"\"\"\n",
    "    Define a rooted hierarchy based on the edges of a spanning tree.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bodyparts: list of str\n",
    "        Ordered list of node names.\n",
    "\n",
    "    skeleton: list of tuples\n",
    "        Edges of the spanning tree as pairs of node names.\n",
    "\n",
    "    root_node: str\n",
    "        The desired root node of the hierarchy\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    node_order: array of shape (num_nodes,)\n",
    "        Integer array specifying an ordering of nodes in which parents\n",
    "        precede children (i.e. a topological ordering).\n",
    "\n",
    "    parents: array of shape (num_nodes,)\n",
    "        Child-parent relationships using the indexes from `node_order`, \n",
    "        such that `parent[i]==j` when `node_order[j]` is the parent of \n",
    "        `node_order[i]`.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        The edges in `skeleton` do not define a spanning tree.     \n",
    "    \"\"\"\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(bodyparts)\n",
    "    G.add_edges_from(skeleton)\n",
    "\n",
    "    if not nx.is_tree(G):\n",
    "        cycles = list(nx.cycle_basis(G))\n",
    "        raise ValueError(\n",
    "            'The skeleton does not define a spanning tree, '\n",
    "            'as it contains the following cycles: {}'.format(cycles))\n",
    "    \n",
    "    if not nx.is_connected(G):\n",
    "        raise ValueError(\n",
    "            'The skeleton does not define a spanning tree, '\n",
    "            'as it contains multiple connected components.')\n",
    "    \n",
    "    node_order = list(nx.dfs_preorder_nodes(G, root_node))\n",
    "    parents = np.zeros(len(node_order), dtype=int)\n",
    "\n",
    "    for i,j in skeleton:\n",
    "        i,j = node_order.index(i), node_order.index(j)\n",
    "        if i<j: parents[j] = i\n",
    "        else: parents[i] = j\n",
    "\n",
    "    node_order = np.array([bodyparts.index(n) for n in node_order])\n",
    "    return node_order, parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "material-prize",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "# from keypoint_sort.util import build_node_hierarchy\n",
    "\n",
    "bodyparts = ['tail_tip',\n",
    "             'tail_base',\n",
    "             'spine_low',\n",
    "             'spine_mid',\n",
    "             'spine_high',\n",
    "             'left_ear',\n",
    "             'right_ear',\n",
    "             'forehead',\n",
    "             'nose_tip',\n",
    "             'left_hind_paw_front',\n",
    "             'left_hind_paw_back',\n",
    "             'right_hind_paw_front',\n",
    "             'right_hind_paw_back',\n",
    "             'left_fore_paw',\n",
    "             'right_fore_paw']\n",
    "\n",
    "skeleton = [\n",
    "    ['tail_base', 'spine_low'],\n",
    "    ['spine_low', 'spine_mid'],\n",
    "    ['spine_mid', 'spine_high'],\n",
    "    ['spine_high', 'left_ear'],\n",
    "    ['spine_high', 'right_ear'],\n",
    "    ['spine_high', 'forehead'],\n",
    "    ['forehead', 'nose_tip'],\n",
    "    ['left_hind_paw_back', 'left_hind_paw_front'],\n",
    "    ['spine_low', 'left_hind_paw_back'],\n",
    "    ['right_hind_paw_back', 'right_hind_paw_front'],\n",
    "    ['spine_low', 'right_hind_paw_back'],\n",
    "    ['spine_high', 'left_fore_paw'],\n",
    "    ['spine_high', 'right_fore_paw']\n",
    "]\n",
    "\n",
    "\n",
    "use_bodyparts = bodyparts[1:]\n",
    "use_bodyparts_ix = np.array([bodyparts.index(bp) for bp in use_bodyparts])\n",
    "edges = np.array(kpms.get_edges(use_bodyparts, skeleton))\n",
    "node_order, parents = build_node_hierarchy(use_bodyparts, skeleton, 'spine_low')\n",
    "edges = np.argsort(node_order)[edges]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-windsor",
   "metadata": {},
   "source": [
    "### Detections only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "accomplished-tampa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb435af0c890477db81d9f5d02892f8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vid_dir = '/n/groups/datta/Jonah/kpms_reviews_6cam_thermistor/raw_data/J01601/20230904_J01601'\n",
    "vid_paths = glob.glob(vid_dir+'/*.avi')\n",
    "\n",
    "all_uvs = []\n",
    "all_confs = []\n",
    "for p in vid_paths:\n",
    "    kp_path = p.replace('.avi','.keypoints.h5')\n",
    "    with h5py.File(kp_path,'r') as h5:\n",
    "        uvs = h5['uv'][()]\n",
    "        confs = h5['conf'][()]\n",
    "        uvs[confs<0.25] = np.nan\n",
    "        all_uvs.append(uvs)\n",
    "        all_confs.append(confs)\n",
    "        \n",
    "\n",
    "\n",
    "centroids = []\n",
    "for uvs in all_uvs:\n",
    "    cen = np.nanmedian(uvs,axis=1)[:,None,:]\n",
    "    cen = kpms.interpolate_keypoints(cen, np.isnan(cen).all(1)[:,None]).squeeze()\n",
    "    cen = gaussian_filter1d(cen, 10, axis=0)\n",
    "    centroids.append(cen)\n",
    "    \n",
    "readers = [OpenCVReader(p) for p in vid_paths]\n",
    "\n",
    "outpath = f'qc_videos/{vid_dir.split(\"/\")[-1]}.detections.mp4'\n",
    "with imageio.get_writer(outpath, pixelformat=\"yuv420p\", fps=30, quality=5) as writer:\n",
    "    for t in tqdm.trange(15000):\n",
    "        overlays = []\n",
    "        for i in range(len(readers)):\n",
    "            im = kpms.overlay_keypoints_on_image(readers[i][t], all_uvs[i][t], edges)\n",
    "            im = kpms.crop_image(im, centroids[i][t], 512)\n",
    "            overlays.append(im[::2,::2])\n",
    "        image = np.vstack([\n",
    "            np.hstack(overlays[:3]),  \n",
    "            np.hstack(overlays[3:])\n",
    "        ])\n",
    "        image = cv2.putText(\n",
    "            image, f\"{t}\", (10, image.shape[0]-10),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.9,\n",
    "            (255,255,255), 2, cv2.LINE_AA\n",
    "        )\n",
    "        writer.append_data(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amateur-authorization",
   "metadata": {},
   "source": [
    "### GIMBAL only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "collaborative-brown",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d70dcfc577a40e39569fb0554cfbe5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# vid_dir = '/n/groups/datta/Jonah/kpms_reviews_6cam_thermistor/raw_data/J01601/20230904_J01601'\n",
    "# calib_path = '/n/groups/datta/Jonah/kpms_reviews_6cam_thermistor/raw_data/calibration/data/20230904_calibration/camera_params.h5'\n",
    "\n",
    "\n",
    "vid_dir = '/n/groups/datta/Jonah/kpms_reviews_6cam_thermistor/raw_data/J01701/20230912_J01701'\n",
    "calib_path = '/n/groups/datta/Jonah/kpms_reviews_6cam_thermistor/raw_data/calibration/data/20230912_calibration/camera_params.h5'\n",
    "\n",
    "all_extrinsics, all_intrinsics, camera_names = mcc.load_calibration(calib_path, 'gimbal')\n",
    "gimbal_positions = median_filter(np.load(f'{vid_dir}/gimbal.npy'),(5,1,1))\n",
    "gimbal_uvs = [mcc.project_points(gimbal_positions, ext, *intr) for ext,intr in zip(all_extrinsics, all_intrinsics)]\n",
    "centroids = gaussian_filter1d(np.mean(gimbal_uvs,axis=2),10,axis=1)\n",
    "    \n",
    "readers = [OpenCVReader(f'{vid_dir}/{c}.avi') for c in camera_names]\n",
    "output_dir = join(vid_dir, \"qc_videos\")\n",
    "if not exists(output_dir): os.mkdir(output_dir)\n",
    "output_path = join(output_dir, f'{vid_dir.split(\"/\")[-1]}.gimbal.mp4')\n",
    "\n",
    "with imageio.get_writer(output_path, pixelformat=\"yuv420p\", fps=30, quality=5) as writer:\n",
    "    for t in tqdm.trange(25000):\n",
    "        overlays = []\n",
    "        for i in range(len(readers)):\n",
    "            im = kpms.overlay_keypoints_on_image(readers[i][t], gimbal_uvs[i][t], edges)\n",
    "            im = kpms.crop_image(im, centroids[i][t], 384)\n",
    "            overlays.append(im)\n",
    "        image = np.vstack([\n",
    "            np.hstack(overlays[:3]),  \n",
    "            np.hstack(overlays[3:])\n",
    "        ])\n",
    "        image = cv2.putText(\n",
    "            image, f\"{t}\", (10, image.shape[0]-10),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.9,\n",
    "            (255,255,255), 2, cv2.LINE_AA\n",
    "        )\n",
    "        writer.append_data(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exceptional-prediction",
   "metadata": {},
   "source": [
    "### Stages videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "interested-security",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f670b542aa834c3ab011e70c80c85d7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "calib_path = '/n/groups/datta/Jonah/kpms_reviews_6cam_thermistor/raw_data/calibration/data/20230904_calibration/camera_params.h5'\n",
    "vid_dir = '/n/groups/datta/Jonah/kpms_reviews_6cam_thermistor/raw_data/J01601/20230904_J01601'\n",
    "\n",
    "all_extrinsics, all_intrinsics, camera_names = mcc.load_calibration(calib_path, 'gimbal')\n",
    "triang_positions = np.load(f'{vid_dir}/robust_triangulation.npy')[:,use_bodyparts_ix][:,node_order]\n",
    "triang_uvs = [mcc.project_points(triang_positions, ext, *intr) for ext,intr in zip(all_extrinsics, all_intrinsics)]\n",
    "gimbal_positions = median_filter(np.load(f'{vid_dir}/gimbal.npy'),(5,1,1))\n",
    "gimbal_uvs = [mcc.project_points(gimbal_positions, ext, *intr) for ext,intr in zip(all_extrinsics, all_intrinsics)]\n",
    "centroids = gaussian_filter1d(np.mean(gimbal_uvs,axis=2),10,axis=1)\n",
    "\n",
    "detection_uvs = []\n",
    "for i,c in tqdm.tqdm(enumerate(camera_names)):\n",
    "    with h5py.File(f'{vid_dir}/{c}.keypoints.h5','r') as h5:\n",
    "        uvs = h5['uv'][()][:,use_bodyparts_ix][:,node_order]\n",
    "        mask = h5['conf'][()][:,use_bodyparts_ix][:,node_order] < 0.25\n",
    "        uvs[mask] = np.nan\n",
    "        detection_uvs.append(uvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "comfortable-swiss",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a93c6faaa5340cd9b387804fb2efef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "readers = [OpenCVReader(f'{vid_dir}/{c}.avi') for c in camera_names]\n",
    "output_path = f'qc_videos/{vid_dir.split(\"/\")[-1]}.stages.mp4'\n",
    "all_uvs = np.stack([detection_uvs,triang_uvs,gimbal_uvs])\n",
    "\n",
    "with imageio.get_writer(\n",
    "    output_path, pixelformat=\"yuv420p\", fps=30, quality=5\n",
    ") as writer:\n",
    "    for i in tqdm.trange(4000):\n",
    "        base_ims = [reader[i] for reader in readers]\n",
    "        frame = []\n",
    "        for uvs,name in zip(all_uvs[:,:,i],['detections','triangulation','gimbal']):\n",
    "            row = []\n",
    "            for j,base_im in enumerate(base_ims):\n",
    "                im = kpms.overlay_keypoints_on_image(base_im.copy(), uvs[j], edges)\n",
    "                im = kpms.crop_image(im, centroids[j,i], 384)\n",
    "                im = cv2.putText(im, name, (10, 36), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1, cv2.LINE_AA)\n",
    "                im = cv2.putText(im, camera_names[j], (10, 18), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1, cv2.LINE_AA)\n",
    "                row.append(im)\n",
    "            frame.append(np.hstack(row))\n",
    "        frame = np.vstack(frame)\n",
    "        frame = cv2.putText(frame, repr(i), (10, frame.shape[0]-12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1, cv2.LINE_AA)\n",
    "        frame = cv2.resize(frame, (1536,768))\n",
    "        writer.append_data(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-action",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
